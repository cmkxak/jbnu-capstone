{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_abnormal_1650191843.npy\n",
      "seq_abnormal_1650191850.npy\n",
      "seq_abnormal_1650191857.npy\n",
      "seq_abnormal_1650191970.npy\n",
      "seq_error_1650192529.npy\n",
      "seq_error_1650192541.npy\n",
      "seq_error_1650192545.npy\n",
      "seq_error_1650192548.npy\n",
      "seq_error_1650192552.npy\n",
      "seq_error_1650192558.npy\n",
      "seq_error_1650192562.npy\n",
      "seq_error_1650192566.npy\n",
      "seq_error_1650192585.npy\n",
      "seq_error_1650192593.npy\n",
      "seq_fall_1650192042.npy\n",
      "seq_fall_1650192044.npy\n",
      "seq_fall_1650192046.npy\n",
      "seq_fall_1650192048.npy\n",
      "seq_fall_1650192049.npy\n",
      "seq_fall_1650192050.npy\n",
      "seq_fall_1650192054.npy\n",
      "seq_fall_1650192056.npy\n",
      "seq_fall_1650192059.npy\n",
      "seq_fall_1650192060.npy\n",
      "seq_fall_1650192062.npy\n",
      "seq_fall_1650192064.npy\n",
      "seq_fall_1650192067.npy\n",
      "seq_fall_1650192069.npy\n",
      "seq_fall_1650192070.npy\n",
      "seq_fall_1650192072.npy\n",
      "seq_fall_1650192075.npy\n",
      "seq_fall_1650192078.npy\n",
      "seq_fall_1650192081.npy\n",
      "seq_fall_1650192084.npy\n",
      "seq_fall_1650192086.npy\n",
      "seq_fall_1650192089.npy\n",
      "seq_fall_1650192092.npy\n",
      "seq_fall_1650192094.npy\n",
      "seq_fall_1650192097.npy\n",
      "seq_fall_1650192099.npy\n",
      "seq_fall_1650192101.npy\n",
      "seq_fall_1650192104.npy\n",
      "seq_fall_1650192107.npy\n",
      "seq_fall_1650192109.npy\n",
      "seq_fall_1650192111.npy\n",
      "seq_fall_1650192113.npy\n",
      "seq_fall_1650192115.npy\n",
      "seq_fall_1650192117.npy\n",
      "seq_fall_1650192119.npy\n",
      "seq_fall_1650192121.npy\n",
      "seq_fall_1650192123.npy\n",
      "seq_fall_1650192125.npy\n",
      "seq_fall_1650192127.npy\n",
      "seq_fall_1650192130.npy\n",
      "seq_fall_1650192132.npy\n",
      "seq_fall_1650192134.npy\n",
      "seq_fall_1650192136.npy\n",
      "seq_fall_1650192137.npy\n",
      "seq_fall_1650192139.npy\n",
      "seq_fall_1650192141.npy\n",
      "seq_fall_1650192143.npy\n",
      "seq_fall_1650192145.npy\n",
      "seq_fall_1650192147.npy\n",
      "seq_fall_1650192150.npy\n",
      "seq_fall_1650192152.npy\n",
      "seq_fall_1650192154.npy\n",
      "seq_fall_1650192156.npy\n",
      "seq_fall_1650192159.npy\n",
      "seq_fall_1650192162.npy\n",
      "seq_fall_1650192164.npy\n",
      "seq_fall_1650192165.npy\n",
      "seq_fall_1650192167.npy\n",
      "seq_lie_1650192307.npy\n",
      "seq_lie_1650192330.npy\n",
      "seq_lie_1650192350.npy\n",
      "seq_lie_1650192369.npy\n",
      "seq_lie_1650192390.npy\n",
      "seq_lie_1650192413.npy\n",
      "seq_lie_1650192433.npy\n",
      "seq_lie_1650192451.npy\n",
      "seq_normal_1650191240.npy\n",
      "seq_normal_1650191265.npy\n",
      "seq_normal_1650191300.npy\n",
      "seq_normal_1650191323.npy\n",
      "seq_normal_1650191354.npy\n",
      "seq_normal_1650191372.npy\n",
      "seq_normal_1650191391.npy\n",
      "seq_normal_1650191409.npy\n",
      "seq_normal_1650191425.npy\n",
      "seq_normal_1650191449.npy\n",
      "seq_normal_1650191464.npy\n",
      "seq_normal_1650191486.npy\n",
      "seq_normal_1650191503.npy\n",
      "seq_normal_1650191507.npy\n",
      "seq_normal_1650191514.npy\n",
      "seq_normal_1650191527.npy\n",
      "seq_normal_1650191535.npy\n",
      "seq_normal_1650191559.npy\n",
      "seq_normal_1650191575.npy\n",
      "seq_normal_1650191594.npy\n",
      "seq_normal_1650191614.npy\n",
      "seq_normal_1650191637.npy\n",
      "seq_normal_1650191646.npy\n",
      "seq_normal_1650191669.npy\n",
      "seq_normal_1650191685.npy\n",
      "seq_normal_1650191705.npy\n",
      "seq_normal_1650191709.npy\n",
      "seq_normal_1650191727.npy\n",
      "seq_normal_1650191742.npy\n",
      "seq_normal_1650191752.npy\n",
      "seq_normal_1650191765.npy\n",
      "seq_normal_1650191774.npy\n",
      "seq_normal_1650191788.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16809, 20, 162)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    'normal',\n",
    "    'abnormal',\n",
    "    'fall',\n",
    "    'lie',\n",
    "    'error'\n",
    "]\n",
    "#여기에 numpy파일을 여러개 load하면 여러개의 동작데이터를 삽입할 수 있음.\n",
    "\n",
    "import os\n",
    "\n",
    "filePath = \"dataset\"\n",
    "data = []\n",
    "idx = 0\n",
    "for (root, directories, files) in os.walk(filePath):\n",
    "    for file in files:\n",
    "        if file.startswith(\"raw\"):# exclude raw dataset\n",
    "            continue\n",
    "        print(file)\n",
    "        file_path = os.path.join(root, file)\n",
    "        if np.load(file_path).shape[0] == 0:# exclude unavailable array\n",
    "            continue\n",
    "        if idx == 0:\n",
    "            data = np.concatenate([\n",
    "                np.load(file_path)\n",
    "            ], axis=0)\n",
    "        data = np.concatenate([\n",
    "            np.array(data),\n",
    "            np.load(file_path)\n",
    "        ], axis=0)\n",
    "        idx += 1\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16809, 20, 161)\n",
      "(16809,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1] # 정답레이블 제거\n",
    "labels = data[:, 0, -1] # 정답레이블 추출\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16809, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions)) # 원핫인코딩 (1,0,0), (0,1,0), (0,0,1)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15128, 20, 161) (15128, 5)\n",
      "(1681, 20, 161) (1681, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2022) # 학습데이터와 검증데이터 분리\n",
    "\n",
    "print(x_train.shape, y_train.shape) # 학습데이터 및 정답레이블\n",
    "print(x_val.shape, y_val.shape) #검증데이터 및 정답레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_2 (GRU)                 (None, 20, 64)            43584     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 20, 64)            0         \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 64)                24960     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,789\n",
      "Trainable params: 70,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    GRU(units=64, activation='relu', input_shape=x_train.shape[1:3], return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    GRU(units=64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 2.7685 - acc: 0.5332\n",
      "Epoch 1: val_acc improved from -inf to 0.69423, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 4s 42ms/step - loss: 2.7657 - acc: 0.5335 - val_loss: 0.9466 - val_acc: 0.6942 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 1.0041 - acc: 0.6591\n",
      "Epoch 2: val_acc improved from 0.69423 to 0.70851, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 37ms/step - loss: 1.0035 - acc: 0.6593 - val_loss: 0.8384 - val_acc: 0.7085 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.8479 - acc: 0.7001\n",
      "Epoch 3: val_acc improved from 0.70851 to 0.74361, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 37ms/step - loss: 0.8476 - acc: 0.7001 - val_loss: 0.7050 - val_acc: 0.7436 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.7030 - acc: 0.7526\n",
      "Epoch 4: val_acc improved from 0.74361 to 0.78822, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 37ms/step - loss: 0.7027 - acc: 0.7528 - val_loss: 0.5980 - val_acc: 0.7882 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5989 - acc: 0.7855\n",
      "Epoch 5: val_acc improved from 0.78822 to 0.82570, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.5985 - acc: 0.7858 - val_loss: 0.5215 - val_acc: 0.8257 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4991 - acc: 0.8170\n",
      "Epoch 6: val_acc improved from 0.82570 to 0.85187, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.4990 - acc: 0.8171 - val_loss: 0.4014 - val_acc: 0.8519 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.4147 - acc: 0.8469\n",
      "Epoch 7: val_acc improved from 0.85187 to 0.87151, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.4157 - acc: 0.8466 - val_loss: 0.3304 - val_acc: 0.8715 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3678 - acc: 0.8636\n",
      "Epoch 8: val_acc improved from 0.87151 to 0.90244, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.3677 - acc: 0.8636 - val_loss: 0.2842 - val_acc: 0.9024 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.3065 - acc: 0.8884\n",
      "Epoch 9: val_acc improved from 0.90244 to 0.91910, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.3064 - acc: 0.8884 - val_loss: 0.2518 - val_acc: 0.9191 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.2628 - acc: 0.9055\n",
      "Epoch 10: val_acc improved from 0.91910 to 0.92385, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.2628 - acc: 0.9055 - val_loss: 0.2265 - val_acc: 0.9239 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.2364 - acc: 0.9170\n",
      "Epoch 11: val_acc improved from 0.92385 to 0.94706, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.2364 - acc: 0.9169 - val_loss: 0.1627 - val_acc: 0.9471 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.2027 - acc: 0.9301\n",
      "Epoch 12: val_acc improved from 0.94706 to 0.95419, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.2026 - acc: 0.9301 - val_loss: 0.1497 - val_acc: 0.9542 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9453\n",
      "Epoch 13: val_acc improved from 0.95419 to 0.96014, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.1556 - acc: 0.9453 - val_loss: 0.1088 - val_acc: 0.9601 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1692 - acc: 0.9408\n",
      "Epoch 14: val_acc improved from 0.96014 to 0.97264, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.1692 - acc: 0.9408 - val_loss: 0.1145 - val_acc: 0.9726 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9574\n",
      "Epoch 15: val_acc did not improve from 0.97264\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.1270 - acc: 0.9574 - val_loss: 0.0936 - val_acc: 0.9691 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9633\n",
      "Epoch 16: val_acc did not improve from 0.97264\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.1119 - acc: 0.9632 - val_loss: 0.0948 - val_acc: 0.9691 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9665\n",
      "Epoch 17: val_acc improved from 0.97264 to 0.99286, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0953 - acc: 0.9666 - val_loss: 0.0415 - val_acc: 0.9929 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9739\n",
      "Epoch 18: val_acc did not improve from 0.99286\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0839 - acc: 0.9740 - val_loss: 0.0501 - val_acc: 0.9881 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9784\n",
      "Epoch 19: val_acc improved from 0.99286 to 0.99346, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0637 - acc: 0.9785 - val_loss: 0.0326 - val_acc: 0.9935 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9791\n",
      "Epoch 20: val_acc did not improve from 0.99346\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0625 - acc: 0.9790 - val_loss: 0.0467 - val_acc: 0.9887 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9823\n",
      "Epoch 21: val_acc did not improve from 0.99346\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0545 - acc: 0.9822 - val_loss: 0.0409 - val_acc: 0.9893 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9751\n",
      "Epoch 22: val_acc improved from 0.99346 to 0.99465, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0819 - acc: 0.9751 - val_loss: 0.0291 - val_acc: 0.9946 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9851\n",
      "Epoch 23: val_acc did not improve from 0.99465\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0458 - acc: 0.9851 - val_loss: 0.0232 - val_acc: 0.9917 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9870\n",
      "Epoch 24: val_acc improved from 0.99465 to 0.99643, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0393 - acc: 0.9870 - val_loss: 0.0151 - val_acc: 0.9964 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9895\n",
      "Epoch 25: val_acc improved from 0.99643 to 0.99762, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0337 - acc: 0.9895 - val_loss: 0.0118 - val_acc: 0.9976 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9842\n",
      "Epoch 26: val_acc did not improve from 0.99762\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0536 - acc: 0.9842 - val_loss: 0.0338 - val_acc: 0.9911 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9814\n",
      "Epoch 27: val_acc did not improve from 0.99762\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0566 - acc: 0.9814 - val_loss: 0.0168 - val_acc: 0.9970 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9900\n",
      "Epoch 28: val_acc did not improve from 0.99762\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0321 - acc: 0.9900 - val_loss: 0.0150 - val_acc: 0.9970 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9903\n",
      "Epoch 29: val_acc improved from 0.99762 to 0.99822, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0339 - acc: 0.9903 - val_loss: 0.0075 - val_acc: 0.9982 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9907\n",
      "Epoch 30: val_acc did not improve from 0.99822\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0331 - acc: 0.9907 - val_loss: 0.0371 - val_acc: 0.9881 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9927\n",
      "Epoch 31: val_acc improved from 0.99822 to 0.99881, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0262 - acc: 0.9927 - val_loss: 0.0047 - val_acc: 0.9988 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9972\n",
      "Epoch 32: val_acc improved from 0.99881 to 1.00000, saving model to models\\modelV3.0_GRU_lying.h5\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.0014 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9941\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0200 - acc: 0.9941 - val_loss: 0.0103 - val_acc: 0.9988 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9922\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0232 - acc: 0.9922 - val_loss: 0.0257 - val_acc: 0.9958 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9909\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0303 - acc: 0.9909 - val_loss: 0.0046 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9939\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0222 - acc: 0.9939 - val_loss: 0.0066 - val_acc: 0.9982 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9935\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0209 - acc: 0.9935 - val_loss: 0.0118 - val_acc: 0.9970 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9883\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 37ms/step - loss: 0.0384 - acc: 0.9885 - val_loss: 0.0207 - val_acc: 0.9923 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9890\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0382 - acc: 0.9890 - val_loss: 0.0104 - val_acc: 0.9970 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9939\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0196 - acc: 0.9939 - val_loss: 0.0050 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9956\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0142 - acc: 0.9956 - val_loss: 0.0051 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9891\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0376 - acc: 0.9890 - val_loss: 0.0174 - val_acc: 0.9935 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9783\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0705 - acc: 0.9783 - val_loss: 0.0103 - val_acc: 0.9982 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9934\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0228 - acc: 0.9934 - val_loss: 0.0080 - val_acc: 0.9982 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9913\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0318 - acc: 0.9913 - val_loss: 0.0176 - val_acc: 0.9970 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9940\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0238 - acc: 0.9940 - val_loss: 0.0073 - val_acc: 0.9982 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9962\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0145 - acc: 0.9962 - val_loss: 0.0074 - val_acc: 0.9970 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9922\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0271 - acc: 0.9922 - val_loss: 0.0156 - val_acc: 0.9964 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9967\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0115 - acc: 0.9967 - val_loss: 0.0029 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9952\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0151 - acc: 0.9952 - val_loss: 0.0034 - val_acc: 0.9988 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9938\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0231 - acc: 0.9939 - val_loss: 0.0045 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9957\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0156 - acc: 0.9957 - val_loss: 0.0093 - val_acc: 0.9976 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9965\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0128 - acc: 0.9965 - val_loss: 0.0091 - val_acc: 0.9970 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9899\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0324 - acc: 0.9900 - val_loss: 0.0102 - val_acc: 0.9982 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9966\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0131 - acc: 0.9966 - val_loss: 0.0017 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9932\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0228 - acc: 0.9933 - val_loss: 0.0140 - val_acc: 0.9958 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9956\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0170 - acc: 0.9956 - val_loss: 0.0018 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9921\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0263 - acc: 0.9921 - val_loss: 0.0250 - val_acc: 0.9911 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9967\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0110 - acc: 0.9967 - val_loss: 4.3301e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9987\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.0060 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9966\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0112 - acc: 0.9966 - val_loss: 0.0045 - val_acc: 0.9982 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9944\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0222 - acc: 0.9944 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9968\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0125 - acc: 0.9968 - val_loss: 0.0050 - val_acc: 0.9982 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9831\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0613 - acc: 0.9831 - val_loss: 0.0054 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9954\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0152 - acc: 0.9954 - val_loss: 0.0073 - val_acc: 0.9976 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9964\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0118 - acc: 0.9964 - val_loss: 0.0027 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9979\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0076 - acc: 0.9980 - val_loss: 0.0058 - val_acc: 0.9982 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9965\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0122 - acc: 0.9965 - val_loss: 0.0142 - val_acc: 0.9946 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9925\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0230 - acc: 0.9924 - val_loss: 0.0147 - val_acc: 0.9970 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9877\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0424 - acc: 0.9877 - val_loss: 0.0050 - val_acc: 0.9988 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9960\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0034 - val_acc: 0.9988 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9980\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0083 - acc: 0.9980 - val_loss: 0.0021 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9954\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0161 - acc: 0.9954 - val_loss: 0.0010 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9974\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0073 - val_acc: 0.9976 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9914\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0294 - acc: 0.9913 - val_loss: 0.0217 - val_acc: 0.9941 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9791\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0716 - acc: 0.9791 - val_loss: 0.0136 - val_acc: 0.9952 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9948\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0175 - acc: 0.9948 - val_loss: 0.0053 - val_acc: 0.9988 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9964\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0110 - acc: 0.9964 - val_loss: 0.0033 - val_acc: 0.9988 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9973\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0087 - acc: 0.9973 - val_loss: 0.0019 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9975\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0111 - acc: 0.9975 - val_loss: 0.0032 - val_acc: 0.9994 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9963\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.0033 - val_acc: 0.9988 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9970\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0033 - val_acc: 0.9988 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9977\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0075 - acc: 0.9977 - val_loss: 0.0020 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 3.1608e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 3.8283e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9991\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 3.5157e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9994\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 1.8327e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0020 - acc: 0.9995 - val_loss: 3.0883e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9987\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 0.0017 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 0.0017 - val_acc: 0.9988 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9977\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 2.2722e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9992\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 1.7624e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9991\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 1.2241e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 3.4770e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9981\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0057 - acc: 0.9981 - val_loss: 0.0117 - val_acc: 0.9970 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9985\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0061 - acc: 0.9985 - val_loss: 9.2863e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9991\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 2.9940e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9986\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0040 - acc: 0.9986 - val_loss: 4.3242e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 8.5300e-04 - acc: 0.9999\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 8.5164e-04 - acc: 0.9999 - val_loss: 4.1152e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9994\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0016 - acc: 0.9994 - val_loss: 2.7117e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9991\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0042 - acc: 0.9991 - val_loss: 0.0020 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9991\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 37ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 5.9390e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9987\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 38ms/step - loss: 0.0033 - acc: 0.9987 - val_loss: 3.0288e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9983\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 37ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0011 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 37ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 3.3278e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9987\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0043 - acc: 0.9987 - val_loss: 3.7657e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 1.8986e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 108/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 4.3890e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9993\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0045 - acc: 0.9993 - val_loss: 6.7778e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 110/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9988\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 1.1248e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 111/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 9.1187e-04 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 112/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9989\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0046 - acc: 0.9989 - val_loss: 0.0061 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 113/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9983\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0088 - acc: 0.9983 - val_loss: 1.6765e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 114/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 1.3880e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 115/200\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 39ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0013 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 116/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 5.9960e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 117/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 7.4816e-04 - acc: 0.9997\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 7.4697e-04 - acc: 0.9997 - val_loss: 3.7515e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 118/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 7.2624e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 119/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9965\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0204 - acc: 0.9965 - val_loss: 0.0589 - val_acc: 0.9822 - lr: 5.0000e-04\n",
      "Epoch 120/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9913\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0314 - acc: 0.9913 - val_loss: 0.0036 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 121/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9989\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0040 - acc: 0.9989 - val_loss: 3.4298e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 122/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0016 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 123/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9997\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0010 - acc: 0.9997 - val_loss: 4.0924e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 124/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9993\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0015 - acc: 0.9993 - val_loss: 7.9634e-04 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 125/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 6.0008e-04 - acc: 0.9999\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 5.9920e-04 - acc: 0.9999 - val_loss: 0.0011 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 126/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.0046 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 127/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9993\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0017 - acc: 0.9993 - val_loss: 0.0057 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 128/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9994\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0035 - val_acc: 0.9988 - lr: 5.0000e-04\n",
      "Epoch 129/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9983\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0066 - acc: 0.9983 - val_loss: 0.0024 - val_acc: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 130/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9995\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0027 - acc: 0.9995 - val_loss: 2.4623e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 131/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 3.8039e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 132/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9989\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0067 - val_acc: 0.9988 - lr: 5.0000e-04\n",
      "Epoch 133/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9994\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0032 - val_acc: 0.9988 - lr: 2.5000e-04\n",
      "Epoch 134/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 7.8752e-04 - acc: 0.9997\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 7.8628e-04 - acc: 0.9997 - val_loss: 0.0015 - val_acc: 0.9988 - lr: 2.5000e-04\n",
      "Epoch 135/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 8.9275e-04 - acc: 0.9997\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 8.9133e-04 - acc: 0.9997 - val_loss: 0.0025 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 136/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 6.0857e-04 - acc: 0.9998\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 6.0760e-04 - acc: 0.9998 - val_loss: 0.0011 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 137/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 2.5228e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 138/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0016 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 139/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 6.4592e-04 - acc: 0.9997\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 6.4494e-04 - acc: 0.9997 - val_loss: 0.0019 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 140/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 2.9541e-04 - acc: 1.0000\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 2.9495e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 141/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 2.0954e-04 - acc: 1.0000\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 2.0923e-04 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 142/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 6.0497e-04 - acc: 0.9997\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 6.0401e-04 - acc: 0.9997 - val_loss: 0.0030 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 143/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 4.1196e-04 - acc: 0.9997\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 4.1131e-04 - acc: 0.9997 - val_loss: 0.0015 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 144/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 2.1170e-04 - acc: 1.0000\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 2.1137e-04 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 145/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 1.9214e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 146/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.0044 - val_acc: 0.9988 - lr: 2.5000e-04\n",
      "Epoch 147/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9995\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0041 - val_acc: 0.9988 - lr: 2.5000e-04\n",
      "Epoch 148/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9990\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 1.3608e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 149/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9993\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0016 - acc: 0.9993 - val_loss: 1.5349e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 150/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9995\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 6.9524e-04 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 151/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9996    \n",
      "Epoch 151: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 2.6991e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 152/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9996\n",
      "Epoch 152: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 2.2581e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 153/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 6.8486e-04 - acc: 0.9998\n",
      "Epoch 153: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 6.8379e-04 - acc: 0.9998 - val_loss: 4.7989e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 154/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 4.4810e-04 - acc: 1.0000\n",
      "Epoch 154: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 4.4949e-04 - acc: 1.0000 - val_loss: 5.1051e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 155/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 155: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0014 - val_acc: 0.9994 - lr: 2.5000e-04\n",
      "Epoch 156/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 8.9744e-04 - acc: 0.9997\n",
      "Epoch 156: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 8.9602e-04 - acc: 0.9997 - val_loss: 3.2931e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 157/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9997    \n",
      "Epoch 157: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 9.6592e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 158/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 9.4828e-04 - acc: 0.9998\n",
      "Epoch 158: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 37ms/step - loss: 9.4678e-04 - acc: 0.9998 - val_loss: 2.4893e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 159/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 159: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 37ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 3.6721e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 160/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 5.9940e-04 - acc: 0.9999\n",
      "Epoch 160: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 5.9861e-04 - acc: 0.9999 - val_loss: 3.1189e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 161/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 3.2270e-04 - acc: 0.9999\n",
      "Epoch 161: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 3.2219e-04 - acc: 0.9999 - val_loss: 1.4617e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 162/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 2.2584e-04 - acc: 0.9999\n",
      "Epoch 162: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 2.6729e-04 - acc: 0.9999 - val_loss: 1.7354e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 163/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9994\n",
      "Epoch 163: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 2.3956e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 164/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992\n",
      "Epoch 164: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 8.2263e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 165/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 3.5395e-04 - acc: 0.9999\n",
      "Epoch 165: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 3.5339e-04 - acc: 0.9999 - val_loss: 9.8799e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 166/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 1.1289e-04 - acc: 1.0000\n",
      "Epoch 166: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 1.1271e-04 - acc: 1.0000 - val_loss: 9.1848e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 167/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 6.1229e-04 - acc: 0.9999\n",
      "Epoch 167: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 6.1211e-04 - acc: 0.9999 - val_loss: 3.0796e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 168/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9989\n",
      "Epoch 168: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0055 - acc: 0.9989 - val_loss: 1.0888e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 169/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 6.1200e-04 - acc: 0.9999\n",
      "Epoch 169: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 6.1103e-04 - acc: 0.9999 - val_loss: 8.3001e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 170/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 170: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 2.8899e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 171/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 4.9437e-04 - acc: 0.9999\n",
      "Epoch 171: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 4.9359e-04 - acc: 0.9999 - val_loss: 4.0069e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 172/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 172: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0015 - acc: 0.9995 - val_loss: 1.7431e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 173/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 5.8442e-04 - acc: 0.9998\n",
      "Epoch 173: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 5.8400e-04 - acc: 0.9998 - val_loss: 3.4316e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 174/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9977\n",
      "Epoch 174: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0121 - acc: 0.9978 - val_loss: 0.0121 - val_acc: 0.9958 - lr: 2.5000e-04\n",
      "Epoch 175/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9983\n",
      "Epoch 175: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0068 - acc: 0.9983 - val_loss: 7.9097e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 176/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 0.9997   \n",
      "Epoch 176: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0010 - acc: 0.9997 - val_loss: 1.0939e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 177/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9997   \n",
      "Epoch 177: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 6.7553e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 178/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 7.0283e-04 - acc: 0.9996\n",
      "Epoch 178: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 7.0171e-04 - acc: 0.9996 - val_loss: 4.3321e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 179/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 4.2082e-04 - acc: 0.9999\n",
      "Epoch 179: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 4.2020e-04 - acc: 0.9999 - val_loss: 5.3750e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 180/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 180: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0094 - val_acc: 0.9982 - lr: 2.5000e-04\n",
      "Epoch 181/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9986\n",
      "Epoch 181: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 0.0045 - acc: 0.9986 - val_loss: 1.0349e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 182/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 5.6512e-04 - acc: 0.9999\n",
      "Epoch 182: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 182: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 5.6423e-04 - acc: 0.9999 - val_loss: 2.2053e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 183/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 5.0806e-04 - acc: 0.9999\n",
      "Epoch 183: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 5.0726e-04 - acc: 0.9999 - val_loss: 2.4543e-05 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 184/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 7.4004e-04 - acc: 0.9997\n",
      "Epoch 184: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 7.3888e-04 - acc: 0.9997 - val_loss: 1.0048e-04 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 185/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 2.3344e-04 - acc: 1.0000\n",
      "Epoch 185: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 2.3445e-04 - acc: 1.0000 - val_loss: 6.3807e-05 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 186/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 2.7034e-04 - acc: 0.9999\n",
      "Epoch 186: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 33ms/step - loss: 2.6996e-04 - acc: 0.9999 - val_loss: 4.0026e-05 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 187/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 4.0683e-04 - acc: 0.9999\n",
      "Epoch 187: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 4.0656e-04 - acc: 0.9999 - val_loss: 1.9011e-05 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 188/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 2.0802e-04 - acc: 0.9999\n",
      "Epoch 188: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 2.0772e-04 - acc: 0.9999 - val_loss: 1.6920e-05 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 189/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 9.1843e-04 - acc: 0.9999\n",
      "Epoch 189: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 9.1788e-04 - acc: 0.9999 - val_loss: 1.9956e-05 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 190/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 4.8877e-04 - acc: 0.9999\n",
      "Epoch 190: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 4.8799e-04 - acc: 0.9999 - val_loss: 4.1875e-05 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 191/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 2.0162e-04 - acc: 1.0000\n",
      "Epoch 191: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 2.0132e-04 - acc: 1.0000 - val_loss: 3.4563e-05 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 192/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 2.9396e-04 - acc: 0.9999\n",
      "Epoch 192: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 2.9351e-04 - acc: 0.9999 - val_loss: 6.6041e-05 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 193/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 6.2108e-04 - acc: 0.9997\n",
      "Epoch 193: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 6.2009e-04 - acc: 0.9997 - val_loss: 9.0886e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 194/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 4.0583e-04 - acc: 0.9999\n",
      "Epoch 194: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 4.0519e-04 - acc: 0.9999 - val_loss: 1.2247e-05 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 195/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 2.1776e-04 - acc: 1.0000\n",
      "Epoch 195: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 2.1742e-04 - acc: 1.0000 - val_loss: 1.7439e-05 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 196/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 1.8541e-04 - acc: 0.9999\n",
      "Epoch 196: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 34ms/step - loss: 1.8512e-04 - acc: 0.9999 - val_loss: 8.2594e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 197/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 4.8529e-04 - acc: 0.9999\n",
      "Epoch 197: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 4.8452e-04 - acc: 0.9999 - val_loss: 7.6259e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 198/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 3.3427e-04 - acc: 0.9998\n",
      "Epoch 198: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 36ms/step - loss: 3.3374e-04 - acc: 0.9998 - val_loss: 5.7787e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 199/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 1.5978e-04 - acc: 1.0000\n",
      "Epoch 199: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 1.6021e-04 - acc: 1.0000 - val_loss: 5.1829e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 200/200\n",
      "59/60 [============================>.] - ETA: 0s - loss: 7.4000e-04 - acc: 0.9999\n",
      "Epoch 200: val_acc did not improve from 1.00000\n",
      "60/60 [==============================] - 2s 35ms/step - loss: 7.3883e-04 - acc: 0.9999 - val_loss: 3.0955e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size = 256,\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/modelV3.0_GRU_lying.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 533,    0],\n",
       "        [   0, 1148]],\n",
       "\n",
       "       [[1599,    0],\n",
       "        [   0,   82]],\n",
       "\n",
       "       [[1568,    0],\n",
       "        [   0,  113]],\n",
       "\n",
       "       [[1382,    0],\n",
       "        [   0,  299]],\n",
       "\n",
       "       [[1642,    0],\n",
       "        [   0,   39]]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/modelV3.0_GRU_lying.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history.model.save('models/modelV3.1_GRU_lying.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
